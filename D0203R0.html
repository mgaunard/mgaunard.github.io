<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<title>Considerations for the design of expressive portable SIMD vectors</title>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"></meta>
<meta name="keywords" content="overloading, operator, smart, objects, references, C++, proposal, ISO/IEC, JTC1, SC22, WG21, N4495"></meta>

<style type="text/css">

#docinfo table {
  border: none;
  border-spacing: 0px;
}

h2 {
  clear: both;
}

@media screen and (min-width: 1280px) {

#info {
  position: fixed;
  left: 80%;
  top: 0;
}

#docinfo, #toc { width: 95%; }

#body {
  width: 80%;
}

}

#toc ul { margin: 0; }
#toc li { margin: 0; }

#toc { margin-bottom: 1em; }

/* github-like markdown */

body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px;
  color: #333;
}
 
body > *:first-child {
  margin-top: 0 !important;
}
 
body > *:last-child {
  margin-bottom: 0 !important;
}
 
a {
  color: #4183C4;
  text-decoration: none;
}
 
a.absent {
  color: #cc0000;
}
 
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
}
 
h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative;
}
 
h2:first-child, h1:first-child, h1:first-child + h2, h3:first-child, h4:first-child, h5:first-child, h6:first-child {
  margin-top: 0;
  padding-top: 0;
}
 
h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  text-decoration: none;
}
 
h1 tt, h1 code {
  font-size: inherit;
}
 
h2 tt, h2 code {
  font-size: inherit;
}
 
h3 tt, h3 code {
  font-size: inherit;
}
 
h4 tt, h4 code {
  font-size: inherit;
}
 
h5 tt, h5 code {
  font-size: inherit;
}
 
h6 tt, h6 code {
  font-size: inherit;
}
 
h1 {
  font-size: 28px;
  color: black;
}
 
h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black;
}
 
h3 {
  font-size: 18px;
}
 
h4 {
  font-size: 16px;
}
 
h5 {
  font-size: 14px;
}
 
h6 {
  color: #777777;
  font-size: 14px;
}
 
p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0;
}
 
hr {
  background: transparent url("http://tinyurl.com/bq5kskr") repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}
 
body > h2:first-child {
  margin-top: 0;
  padding-top: 0;
}
 
body > h1:first-child {
  margin-top: 0;
  padding-top: 0;
}
 
body > h1:first-child + h2 {
  margin-top: 0;
  padding-top: 0;
}
 
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0;
}
 
a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}
 
h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0;
}
 
li p.first {
  display: inline-block;
}
 
ul, ol {
  padding-left: 30px;
}
 
ul :first-child, ol :first-child {
  margin-top: 0;
}
 
ul :last-child, ol :last-child {
  margin-bottom: 0;
}
 
dl {
  padding: 0;
}
 
dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}
 
dl dt:first-child {
  padding: 0;
}
 
dl dt > :first-child {
  margin-top: 0;
}
 
dl dt > :last-child {
  margin-bottom: 0;
}
 
dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}
 
dl dd > :first-child {
  margin-top: 0;
}
 
dl dd > :last-child {
  margin-bottom: 0;
}
 
blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777;
}
 
blockquote > :first-child {
  margin-top: 0;
}
 
blockquote > :last-child {
  margin-bottom: 0;
}
 
table {
  padding: 0;
}
table tr {
  border-top: 1px solid #cccccc;
  background-color: white;
  margin: 0;
  padding: 0;
}
 
table tr:nth-child(2n) {
  background-color: #f8f8f8;
}
 
table tr th {
  font-weight: bold;
  border: 1px solid #cccccc;
  text-align: left;
  margin: 0;
  padding: 6px 13px;
}
 
table tr td {
  border: 1px solid #cccccc;
  text-align: left;
  margin: 0;
  padding: 6px 13px;
}
 
table tr th :first-child, table tr td :first-child {
  margin-top: 0;
}
 
table tr th :last-child, table tr td :last-child {
  margin-bottom: 0;
}
 
img {
  max-width: 100%;
}
 
span.frame {
  display: block;
  overflow: hidden;
}
 
span.frame > span {
  border: 1px solid #dddddd;
  display: block;
  float: left;
  overflow: hidden;
  margin: 13px 0 0;
  padding: 7px;
  width: auto;
}
 
span.frame span img {
  display: block;
  float: left;
}
 
span.frame span span {
  clear: both;
  color: #333333;
  display: block;
  padding: 5px 0 0;
}
 
span.align-center {
  display: block;
  overflow: hidden;
  clear: both;
}
 
span.align-center > span {
  display: block;
  overflow: hidden;
  margin: 13px auto 0;
  text-align: center;
}
 
span.align-center span img {
  margin: 0 auto;
  text-align: center;
}
 
span.align-right {
  display: block;
  overflow: hidden;
  clear: both;
}
 
span.align-right > span {
  display: block;
  overflow: hidden;
  margin: 13px 0 0;
  text-align: right;
}
 
span.align-right span img {
  margin: 0;
  text-align: right;
}
 
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left;
}
 
span.float-left span {
  margin: 13px 0 0;
}
 
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right;
}
 
span.float-right > span {
  display: block;
  overflow: hidden;
  margin: 13px auto 0;
  text-align: right;
}
 
code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px;
}
 
pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}
 
.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}
 
pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}
 
pre code, pre tt {
  background-color: transparent;
  border: none;
}

/*

Highlight style
github.com style (c) Vasily Polovnyov <vast@whiteants.net>

*/

.hljs {
  display: block;
  overflow-x: auto;
  padding: 0.5em;
  color: #333;
  background: #f8f8f8;
  -webkit-text-size-adjust: none;
}

.hljs-comment,
.diff .hljs-header,
.hljs-javadoc {
  color: #998;
  font-style: italic;
}

.hljs-keyword,
.css .rule .hljs-keyword,
.hljs-winutils,
.nginx .hljs-title,
.hljs-subst,
.hljs-request,
.hljs-status {
  color: #333;
  font-weight: bold;
}

.hljs-number,
.hljs-hexcolor,
.ruby .hljs-constant {
  color: #008080;
}

.hljs-string,
.hljs-tag .hljs-value,
.hljs-phpdoc,
.hljs-dartdoc,
.tex .hljs-formula {
  color: #d14;
}

.hljs-title,
.hljs-id,
.scss .hljs-preprocessor {
  color: #900;
  font-weight: bold;
}

.hljs-list .hljs-keyword,
.hljs-subst {
  font-weight: normal;
}

.hljs-class .hljs-title,
.hljs-type,
.vhdl .hljs-literal,
.tex .hljs-command {
  color: #458;
  font-weight: bold;
}

.hljs-tag,
.hljs-tag .hljs-title,
.hljs-rule .hljs-property,
.django .hljs-tag .hljs-keyword {
  color: #000080;
  font-weight: normal;
}

.hljs-attribute,
.hljs-variable,
.lisp .hljs-body,
.hljs-name {
  color: #008080;
}

.hljs-regexp {
  color: #009926;
}

.hljs-symbol,
.ruby .hljs-symbol .hljs-string,
.lisp .hljs-keyword,
.clojure .hljs-keyword,
.scheme .hljs-keyword,
.tex .hljs-special,
.hljs-prompt {
  color: #990073;
}

.hljs-built_in {
  color: #0086b3;
}

.hljs-preprocessor,
.hljs-pragma,
.hljs-pi,
.hljs-doctype,
.hljs-shebang,
.hljs-cdata {
  color: #999;
  font-weight: bold;
}

.hljs-deletion {
  background: #fdd;
}

.hljs-addition {
  background: #dfd;
}

.diff .hljs-change {
  background: #0086b3;
}

.hljs-chunk {
  color: #aaa;
}


</style>

<script>
!function(e){"undefined"!=typeof exports?e(exports):(window.hljs=e({}),"function"==typeof define&&define.amd&&define([],function(){return window.hljs}))}(function(e){function n(e){return e.replace(/&/gm,"&amp;").replace(/</gm,"&lt;").replace(/>/gm,"&gt;")}function t(e){return e.nodeName.toLowerCase()}function r(e,n){var t=e&&e.exec(n);return t&&0==t.index}function a(e){var n=(e.className+" "+(e.parentNode?e.parentNode.className:"")).split(/\s+/);return n=n.map(function(e){return e.replace(/^lang(uage)?-/,"")}),n.filter(function(e){return N(e)||/no(-?)highlight|plain|text/.test(e)})[0]}function i(e,n){var t,r={};for(t in e)r[t]=e[t];if(n)for(t in n)r[t]=n[t];return r}function o(e){var n=[];return function r(e,a){for(var i=e.firstChild;i;i=i.nextSibling)3==i.nodeType?a+=i.nodeValue.length:1==i.nodeType&&(n.push({event:"start",offset:a,node:i}),a=r(i,a),t(i).match(/br|hr|img|input/)||n.push({event:"stop",offset:a,node:i}));return a}(e,0),n}function u(e,r,a){function i(){return e.length&&r.length?e[0].offset!=r[0].offset?e[0].offset<r[0].offset?e:r:"start"==r[0].event?e:r:e.length?e:r}function o(e){function r(e){return" "+e.nodeName+'="'+n(e.value)+'"'}l+="<"+t(e)+Array.prototype.map.call(e.attributes,r).join("")+">"}function u(e){l+="</"+t(e)+">"}function c(e){("start"==e.event?o:u)(e.node)}for(var s=0,l="",f=[];e.length||r.length;){var g=i();if(l+=n(a.substr(s,g[0].offset-s)),s=g[0].offset,g==e){f.reverse().forEach(u);do c(g.splice(0,1)[0]),g=i();while(g==e&&g.length&&g[0].offset==s);f.reverse().forEach(o)}else"start"==g[0].event?f.push(g[0].node):f.pop(),c(g.splice(0,1)[0])}return l+n(a.substr(s))}function c(e){function n(e){return e&&e.source||e}function t(t,r){return new RegExp(n(t),"m"+(e.cI?"i":"")+(r?"g":""))}function r(a,o){if(!a.compiled){if(a.compiled=!0,a.k=a.k||a.bK,a.k){var u={},c=function(n,t){e.cI&&(t=t.toLowerCase()),t.split(" ").forEach(function(e){var t=e.split("|");u[t[0]]=[n,t[1]?Number(t[1]):1]})};"string"==typeof a.k?c("keyword",a.k):Object.keys(a.k).forEach(function(e){c(e,a.k[e])}),a.k=u}a.lR=t(a.l||/\b\w+\b/,!0),o&&(a.bK&&(a.b="\\b("+a.bK.split(" ").join("|")+")\\b"),a.b||(a.b=/\B|\b/),a.bR=t(a.b),a.e||a.eW||(a.e=/\B|\b/),a.e&&(a.eR=t(a.e)),a.tE=n(a.e)||"",a.eW&&o.tE&&(a.tE+=(a.e?"|":"")+o.tE)),a.i&&(a.iR=t(a.i)),void 0===a.r&&(a.r=1),a.c||(a.c=[]);var s=[];a.c.forEach(function(e){e.v?e.v.forEach(function(n){s.push(i(e,n))}):s.push("self"==e?a:e)}),a.c=s,a.c.forEach(function(e){r(e,a)}),a.starts&&r(a.starts,o);var l=a.c.map(function(e){return e.bK?"\\.?("+e.b+")\\.?":e.b}).concat([a.tE,a.i]).map(n).filter(Boolean);a.t=l.length?t(l.join("|"),!0):{exec:function(){return null}}}}r(e)}function s(e,t,a,i){function o(e,n){for(var t=0;t<n.c.length;t++)if(r(n.c[t].bR,e))return n.c[t]}function u(e,n){if(r(e.eR,n)){for(;e.endsParent&&e.parent;)e=e.parent;return e}return e.eW?u(e.parent,n):void 0}function f(e,n){return!a&&r(n.iR,e)}function g(e,n){var t=E.cI?n[0].toLowerCase():n[0];return e.k.hasOwnProperty(t)&&e.k[t]}function p(e,n,t,r){var a=r?"":x.classPrefix,i='<span class="'+a,o=t?"":"</span>";return i+=e+'">',i+n+o}function d(){if(!L.k)return n(y);var e="",t=0;L.lR.lastIndex=0;for(var r=L.lR.exec(y);r;){e+=n(y.substr(t,r.index-t));var a=g(L,r);a?(B+=a[1],e+=p(a[0],n(r[0]))):e+=n(r[0]),t=L.lR.lastIndex,r=L.lR.exec(y)}return e+n(y.substr(t))}function h(){if(L.sL&&!w[L.sL])return n(y);var e=L.sL?s(L.sL,y,!0,M[L.sL]):l(y);return L.r>0&&(B+=e.r),"continuous"==L.subLanguageMode&&(M[L.sL]=e.top),p(e.language,e.value,!1,!0)}function b(){return void 0!==L.sL?h():d()}function v(e,t){var r=e.cN?p(e.cN,"",!0):"";e.rB?(k+=r,y=""):e.eB?(k+=n(t)+r,y=""):(k+=r,y=t),L=Object.create(e,{parent:{value:L}})}function m(e,t){if(y+=e,void 0===t)return k+=b(),0;var r=o(t,L);if(r)return k+=b(),v(r,t),r.rB?0:t.length;var a=u(L,t);if(a){var i=L;i.rE||i.eE||(y+=t),k+=b();do L.cN&&(k+="</span>"),B+=L.r,L=L.parent;while(L!=a.parent);return i.eE&&(k+=n(t)),y="",a.starts&&v(a.starts,""),i.rE?0:t.length}if(f(t,L))throw new Error('Illegal lexeme "'+t+'" for mode "'+(L.cN||"<unnamed>")+'"');return y+=t,t.length||1}var E=N(e);if(!E)throw new Error('Unknown language: "'+e+'"');c(E);var R,L=i||E,M={},k="";for(R=L;R!=E;R=R.parent)R.cN&&(k=p(R.cN,"",!0)+k);var y="",B=0;try{for(var C,j,I=0;;){if(L.t.lastIndex=I,C=L.t.exec(t),!C)break;j=m(t.substr(I,C.index-I),C[0]),I=C.index+j}for(m(t.substr(I)),R=L;R.parent;R=R.parent)R.cN&&(k+="</span>");return{r:B,value:k,language:e,top:L}}catch(S){if(-1!=S.message.indexOf("Illegal"))return{r:0,value:n(t)};throw S}}function l(e,t){t=t||x.languages||Object.keys(w);var r={r:0,value:n(e)},a=r;return t.forEach(function(n){if(N(n)){var t=s(n,e,!1);t.language=n,t.r>a.r&&(a=t),t.r>r.r&&(a=r,r=t)}}),a.language&&(r.second_best=a),r}function f(e){return x.tabReplace&&(e=e.replace(/^((<[^>]+>|\t)+)/gm,function(e,n){return n.replace(/\t/g,x.tabReplace)})),x.useBR&&(e=e.replace(/\n/g,"<br>")),e}function g(e,n,t){var r=n?E[n]:t,a=[e.trim()];return e.match(/\bhljs\b/)||a.push("hljs"),-1===e.indexOf(r)&&a.push(r),a.join(" ").trim()}function p(e){var n=a(e);if(!/no(-?)highlight|plain|text/.test(n)){var t;x.useBR?(t=document.createElementNS("http://www.w3.org/1999/xhtml","div"),t.innerHTML=e.innerHTML.replace(/\n/g,"").replace(/<br[ \/]*>/g,"\n")):t=e;var r=t.textContent,i=n?s(n,r,!0):l(r),c=o(t);if(c.length){var p=document.createElementNS("http://www.w3.org/1999/xhtml","div");p.innerHTML=i.value,i.value=u(c,o(p),r)}i.value=f(i.value),e.innerHTML=i.value,e.className=g(e.className,n,i.language),e.result={language:i.language,re:i.r},i.second_best&&(e.second_best={language:i.second_best.language,re:i.second_best.r})}}function d(e){x=i(x,e)}function h(){if(!h.called){h.called=!0;var e=document.querySelectorAll("pre code");Array.prototype.forEach.call(e,p)}}function b(){addEventListener("DOMContentLoaded",h,!1),addEventListener("load",h,!1)}function v(n,t){var r=w[n]=t(e);r.aliases&&r.aliases.forEach(function(e){E[e]=n})}function m(){return Object.keys(w)}function N(e){return w[e]||w[E[e]]}var x={classPrefix:"hljs-",tabReplace:null,useBR:!1,languages:void 0},w={},E={};return e.highlight=s,e.highlightAuto=l,e.fixMarkup=f,e.highlightBlock=p,e.configure=d,e.initHighlighting=h,e.initHighlightingOnLoad=b,e.registerLanguage=v,e.listLanguages=m,e.getLanguage=N,e.inherit=i,e.IR="[a-zA-Z]\\w*",e.UIR="[a-zA-Z_]\\w*",e.NR="\\b\\d+(\\.\\d+)?",e.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)",e.BNR="\\b(0b[01]+)",e.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|-|-=|/=|/|:|;|<<|<<=|<=|<|===|==|=|>>>=|>>=|>=|>>>|>>|>|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~",e.BE={b:"\\\\[\\s\\S]",r:0},e.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[e.BE]},e.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[e.BE]},e.PWM={b:/\b(a|an|the|are|I|I'm|isn't|don't|doesn't|won't|but|just|should|pretty|simply|enough|gonna|going|wtf|so|such)\b/},e.C=function(n,t,r){var a=e.inherit({cN:"comment",b:n,e:t,c:[]},r||{});return a.c.push(e.PWM),a},e.CLCM=e.C("//","$"),e.CBCM=e.C("/\\*","\\*/"),e.HCM=e.C("#","$"),e.NM={cN:"number",b:e.NR,r:0},e.CNM={cN:"number",b:e.CNR,r:0},e.BNM={cN:"number",b:e.BNR,r:0},e.CSSNM={cN:"number",b:e.NR+"(%|em|ex|ch|rem|vw|vh|vmin|vmax|cm|mm|in|pt|pc|px|deg|grad|rad|turn|s|ms|Hz|kHz|dpi|dpcm|dppx)?",r:0},e.RM={cN:"regexp",b:/\//,e:/\/[gimuy]*/,i:/\n/,c:[e.BE,{b:/\[/,e:/\]/,r:0,c:[e.BE]}]},e.TM={cN:"title",b:e.IR,r:0},e.UTM={cN:"title",b:e.UIR,r:0},e});hljs.registerLanguage("cpp",function(t){var i={keyword:"false int float while private char catch export virtual operator sizeof dynamic_cast|10 typedef const_cast|10 const struct for static_cast|10 union namespace unsigned long volatile static protected bool template mutable if public friend do goto auto void enum else break extern using true class asm case typeid short reinterpret_cast|10 default double register explicit signed typename try this switch continue wchar_t inline delete alignof char16_t char32_t constexpr decltype noexcept nullptr static_assert thread_local restrict _Bool complex _Complex _Imaginary intmax_t uintmax_t int8_t uint8_t int16_t uint16_t int32_t uint32_t  int64_t uint64_t int_least8_t uint_least8_t int_least16_t uint_least16_t int_least32_t uint_least32_t int_least64_t uint_least64_t int_fast8_t uint_fast8_t int_fast16_t uint_fast16_t int_fast32_t uint_fast32_t int_fast64_t uint_fast64_t intptr_t uintptr_t atomic_bool atomic_char atomic_schar atomic_uchar atomic_short atomic_ushort atomic_int atomic_uint atomic_long atomic_ulong atomic_llong atomic_ullong atomic_wchar_t atomic_char16_t atomic_char32_t atomic_intmax_t atomic_uintmax_t atomic_intptr_t atomic_uintptr_t atomic_size_t atomic_ptrdiff_t atomic_int_least8_t atomic_int_least16_t atomic_int_least32_t atomic_int_least64_t atomic_uint_least8_t atomic_uint_least16_t atomic_uint_least32_t atomic_uint_least64_t atomic_int_fast8_t atomic_int_fast16_t atomic_int_fast32_t atomic_int_fast64_t atomic_uint_fast8_t atomic_uint_fast16_t atomic_uint_fast32_t atomic_uint_fast64_t",built_in:"std string cin cout cerr clog stringstream istringstream ostringstream auto_ptr deque list queue stack vector map set bitset multiset multimap unordered_set unordered_map unordered_multiset unordered_multimap array shared_ptr abort abs acos asin atan2 atan calloc ceil cosh cos exit exp fabs floor fmod fprintf fputs free frexp fscanf isalnum isalpha iscntrl isdigit isgraph islower isprint ispunct isspace isupper isxdigit tolower toupper labs ldexp log10 log malloc memchr memcmp memcpy memset modf pow printf putchar puts scanf sinh sin snprintf sprintf sqrt sscanf strcat strchr strcmp strcpy strcspn strlen strncat strncmp strncpy strpbrk strrchr strspn strstr tanh tan vfprintf vprintf vsprintf"};return{aliases:["c","cc","h","c++","h++","hpp"],k:i,i:"</",c:[t.CLCM,t.CBCM,t.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},t.CNM,{cN:"preprocessor",b:"#",e:"$",k:"if else elif endif define undef warning error line pragma",c:[{b:/\\\n/,r:0},{b:'include\\s*[<"]',e:'[>"]',k:"include",i:"\\n"},t.CLCM]},{b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:i,c:["self"]},{b:t.IR+"::",k:i},{bK:"new throw return else",r:0},{cN:"function",b:"("+t.IR+"\\s+)+"+t.IR+"\\s*\\(",rB:!0,e:/[{;=]/,eE:!0,k:i,c:[{b:t.IR+"\\s*\\(",rB:!0,c:[t.TM],r:0},{cN:"params",b:/\(/,e:/\)/,k:i,r:0,c:[t.CBCM]},t.CLCM,t.CBCM]}]}});

window.onload = function()
{
	/* force all code elements to be C++ */
    var code_elements = document.getElementsByTagName("code");
    for(var i=0; i<code_elements.length; ++i)
    {
	    code_elements[i].className = 'cpp';
    }

    hljs.initHighlighting();
}
</script>

</head>
<body>

  <h1>Considerations for the design of expressive portable SIMD vectors</h1>

<div id="info">

<div id="docinfo">
  <table border="1">
    <tr> <th>Doc. No.:</th> <td>D0203R0</td> </tr>
    <tr> <th>Date:</th>     <td>2016-01-26</td> </tr>
    <tr> <th>Project:</th>  <td>Programming Language C++, SG14 Low Latency</td> </tr>
    <tr> <th>Reply To:</th> <td>Mathias Gaunard &lt;<script type="text/javascript">
<!--
h='&#98;&#108;&#x6f;&#x6f;&#x6d;&#98;&#x65;&#114;&#x67;&#46;&#110;&#x65;&#116;';a='&#64;';n='&#x6d;&#x67;&#x61;&#x75;&#110;&#x61;&#114;&#100;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'" clas'+'s="em' + 'ail">'+e+'<\/'+'a'+'>');
// -->
</script><noscript>&#x6d;&#x67;&#x61;&#x75;&#110;&#x61;&#114;&#100;&#32;&#x61;&#116;&#32;&#98;&#108;&#x6f;&#x6f;&#x6d;&#98;&#x65;&#114;&#x67;&#32;&#100;&#x6f;&#116;&#32;&#110;&#x65;&#116;</noscript>&gt;</td> </tr>
  </table>
  </div>

<div id="toc">
<p>Table of Contents:</p>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#background">Background</a></li>
<li><a href="#number-of-elements-in-a-simd-vector">Number of elements in a SIMD vector</a><ul>
<li><a href="#relationship-between-vectors-of-different-types">Relationship between vectors of different types</a></li>
<li><a href="#user-defined-number-of-elements-of-the-simd-vector">User-defined number of elements of the SIMD vector</a></li>
</ul></li>
<li><a href="#missing-functionality">Missing functionality</a><ul>
<li><a href="#combining-operations">Combining operations</a></li>
<li><a href="#promotion-and-conversion-operations">Promotion and conversion operations</a></li>
<li><a href="#shuffle-operations">Shuffle operations</a></li>
</ul></li>
<li><a href="#implementation-concerns">Implementation concerns</a><ul>
<li><a href="#aliasing">Aliasing</a></li>
<li><a href="#size-of-simd-vector-object">Size of SIMD vector object</a></li>
<li><a href="#impact-of-calling-conventions">Impact of calling conventions</a></li>
</ul></li>
<li><a href="#syntax">Syntax</a><ul>
<li><a href="#mask-and-bools">Mask and bools</a></li>
<li><a href="#expression-templates-for-syntactic-sugar">Expression templates for syntactic sugar</a></li>
</ul></li>
<li><a href="#references">References</a></li>
</ul>
</div>

</div>

<div id="body">
<h2 id="introduction">Introduction</h2>
<p>Single Instruction, Multiple Data (SIMD) is a class of computers that operate the same operation on multiple elements of data in parallel, akin to vector processing. Modern computers provide SIMD instructions that operate on special registers representing short vectors, typically of a few words in size, and the process of converting normal control flow to SIMD control flow is referred to as vectorization.</p>
<p>Two approaches have been considered to provide C++ programmers with the ability to make use of Single Instruction, Multiple Data (SIMD) architectures:</p>
<ul>
<li>annotations on loops to direct automatic vectorization.</li>
<li>explicit usage of short vectors within the type system.</li>
</ul>
<p>This paper covers the second approach exclusively. The subject has already been covered in previous papers: <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3571.pdf">N3571</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4184.pdf">N4184</a> and a number of supporting papers.</p>
<p>The considerations are in this paper cover how to design the API of SIMD vectors so that the provided programming paradigm can be sufficiently expressive to address many applications while also taking into account the variability of hardware support.</p>
<h2 id="background">Background</h2>
<p>The author of this paper is one of the authors of the original SIMD proposal <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3571.pdf">N3571</a> as well as the Boost.SIMD (not a Boost library, candidate for inclusion into Boost) and NT² libraries.</p>
<p>Particularly of interest to the committee, the Boost.SIMD library, through its various authors, has explored the feasibility of implementing all C++ transcendental functions on SIMD types, portably across several hardware platforms with a minimal abstraction layer. This has led to some insight as to what is required from the API and what were in retrospect bad design decisions.</p>
<h2 id="number-of-elements-in-a-simd-vector">Number of elements in a SIMD vector</h2>
<h3 id="relationship-between-vectors-of-different-types">Relationship between vectors of different types</h3>
<p>SIMD registers of, say, 128 bits, are typically able to contain 4 32-bit values or 2 64-bit values; the same can be generalized to SIMD registers of various bit-widths <code>width</code> with the relationship that for any arithmetic types <code>T</code> and <code>U</code>, <code>vector&lt;T&gt;::static_size * sizeof(T) == vector&lt;U&gt;::static_size * sizeof(U) == width/CHAR_BIT</code>.</p>
<p>This relationship is useful and programmers will typically rely on it when promoting smaller types to larger ones: promoting a vector of 4 single-precision floats will give 2 vectors of 2 doubles each. Example uses of that technique is for mixed-precision programming, where part of a double-precision computation will be done using single-precision to quickly compute an approximation using the augmented parallelization, then refining it back with double precision. Signal processing is somewhat similar: you might have to promote a 8-bit integer stream to 16-bit during computation to avoid overflows.</p>
<p>One may also want to work together with both floating-point and integers vectors of relatable sizes when, for example, manipulating the mantissa or exponent of the floating-point directly, as is required to achieve sufficient accuracy for a number of algorithms, like exponentiation.</p>
<p>However, there are good reasons why an implementation may choose not to satisfy this property: some architectures provide SIMD instructions for some types, but not others. (older Altivec and NEON don’t have double precision, AVX pre-AVX2 doesn’t have integers, etc.)</p>
<p><strong>Conclusion</strong>: to write portable code, it is either required that vectors for all types use the same register width, or that the user may choose himself the number of elements of the vectors.</p>
<p><strong>Suggestion</strong>: don’t specify any relationship between vectors for different types, but allow the default size to be overridable.</p>
<h3 id="user-defined-number-of-elements-of-the-simd-vector">User-defined number of elements of the SIMD vector</h3>
<p>In the latest proposal, the number of elements of a SIMD vector is implementation-defined to the most appropriate one for the target architecture, leading to variations across implementations.</p>
<p>The author of <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4184.pdf">N4184</a> made the claim that all code could, and should, be written in a way that is agnostic of the number of elements, demonstrating for example how to achieve this with general matrix-matrix multiplication <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4454.pdf">N4454</a>, and that there is therefore no need to provide tools to cater to bad programming practices.</p>
<h4 id="generalization-is-not-always-easy">Generalization is not always easy</h4>
<p>The author of this paper believes this lacks practicality and might be too idealistic; most existing code today using explicit SIMD vectors, regardless of programming language, is programmed with a specific size in mind and cannot easily be generalized to an arbitrary number of elements. Some algorithms also just cannot necessarily be expressed in a size-agnostic away, at least not without heavy meta-programming: the Fast Fourier Transform butterfly schemes<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> or the bitonic merge networks of AA-sort<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>, that both require shuffling around a number of values across vectors, are a good example of this. Even some matrix multiplication algorithms, like those used in state-of-the-art libraries, use intra-register operations to transpose values and cannot be written as simply as in <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4454.pdf">N4454</a>.</p>
<h4 id="data-can-be-small-and-not-chunkable">Data can be small and not chunkable</h4>
<p>Sometimes, one only has a given small number of values for which they’d like to operate on parallel. While one may argue that this is a design problem and memory should be rearranged in a more structure-of-arrays layout, it might be that it not possible due to memory constraints or that the problem does not offer other dimensions with more parallization potential anyway.</p>
<h4 id="sized-vectors-give-a-better-api-when-multiple-types-are-involved">Sized vectors give a better API when multiple types are involved</h4>
<p>Finally, enabling explicit number of elements allow to provide clearer and more high-level interfaces when dealing with inputs of different types.</p>
<pre><code>simd_vector&lt;double, N&gt; ldexp(simd_vector&lt;double, N&gt; x, simd_vector&lt;int, N&gt; exp);</code></pre>
<p>is a fairly natural declaration of the standard <code>double ldexp(double x, int exp);</code> function extended to SIMD.</p>
<p>However, assuming that a double is 64-bit and an int 32-bit, this means that <code>x</code> and <code>exp</code> would not have the same number of fixed-width SIMD registers.</p>
<p>The alternatives, which would only work if all vectors used the same SIMD register width, would be as follows:</p>
<pre><code>// only read low half of `exp&#39;
simd_vector&lt;double&gt; ldexp(simd_vector&lt;double&gt; x, simd_vector&lt;int&gt; exp);

// as many values for both `x&#39; and `exp
array&lt;simd_vector&lt;double&gt;, 2&gt; ldexp(array&lt;simd_vector&lt;double&gt;, 2&gt; x, simd_vector&lt;int&gt; exp);</code></pre>
<p>Other problems with this approach for example is when computation requires promotion, you end up with twice as many variables, and need to repeat computations on each of them, which is not a nice programming model.</p>
<h4 id="sized-vectors-better-address-architectures-with-multiples-widths">Sized vectors better address architectures with multiples widths</h4>
<p>Some architectures like NEON also have two vector sizes: 64-bit and 128-bit, and depending of which one you use you halve the number of registers available in half. Some instructions will only be defined on the smaller or larger vectors, for valid reasons (ex: full multiplication: int32x2 * int32x2 -&gt; int64x2; promotion: int32x2 -&gt; int64x2)</p>
<p>Multiple register sizes need to be able to exist in the same program to make the most of those architectures; forcing a single size would ignore more than half of the instruction set.</p>
<p><strong>Conclusion</strong>: being able to specify the size explicitly is useful for applications that are specific to a given size and also gives a nice API to work with, even if that means that a vector can actually be represented by multiple registers</p>
<p><strong>Suggestion</strong>: make vector be defined as</p>
<pre><code>template&lt;class T, class X = /* implementation-defined ABI tag */&gt;
int best_size_v = /* implementation-defined */;

template&lt;class T, int N = best_size_v&lt;T&gt;, class X = /* implementation-defined ABI tag */&gt;
struct simd_vector;</code></pre>
<p>with <code>N</code> any power of 2 up to a certain value.</p>
<h2 id="missing-functionality">Missing functionality</h2>
<h3 id="combining-operations">Combining operations</h3>
<p>If vectors of arbitrary power-of-2 sizes can be defined, it would be useful to provide functions to combine/slice vectors into larger/smaller ones.</p>
<pre><code>template&lt;class T, int N&gt;
simd_vector&lt;T, N*2&gt; combine(simd_vector&lt;T, N&gt; a, simd_vector&lt;T, N&gt; b);

template&lt;class T, int N&gt;
array&lt;simd_vector&lt;T, N/2&gt;, 2&gt; slice(simd_vector&lt;T, N&gt; a);</code></pre>
<h3 id="promotion-and-conversion-operations">Promotion and conversion operations</h3>
<p>Converting between integer and floating-point, and promoting/demoting types are core features that are missing from <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4184.pdf">N4184</a>, and that have important repercussions on the design of the API.</p>
<p>Various options are possible, but the most generic one would be to provide something like</p>
<pre><code>vector&lt;T, N&gt; a;
vector&lt;U, N&gt; b = simd_cast&lt;U&gt;(a);</code></pre>
<h3 id="shuffle-operations">Shuffle operations</h3>
<p>Shuffle operations, i.e. operations that reorder the elements within a SIMD register, are also missing entirely from <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4184.pdf">N4184</a>. Given that some SIMD architectures have entire units of the hardware dedicating to permuting all values quickly, it seems a shame not to provide access to that functionality.</p>
<p>Anything involving shuffles would typically not be easy to generalize to arbitrary sizes, though a few patterns can be made size-agnostic.</p>
<pre><code>template&lt;int... I, class T&gt;
simd_vector&lt;T, sizeof...(I)&gt; shuffle(simd_vector&lt;T, sizeof...(I)&gt; a);</code></pre>
<p><em>Semantics</em>: <code>simd_vector&lt;T, sizeof...(I)&gt;{ (I &lt; 0 ? 0 : a[I])... };</code></p>
<pre><code>template&lt;int... I, class T&gt;
simd_vector&lt;T, sizeof...(I)&gt; shuffle(simd_vector&lt;T, sizeof...(I)&gt; a, simd_vector&lt;T, sizeof...(I)&gt; b);</code></pre>
<p><em>Semantics</em>: <code>slice(shuffle&lt;I..., I...&gt;(combine(a, b)))[0]</code></p>
<p>Note: this definition of shuffle is compatible with GCC <code>__builtin_shuffle</code>, Clang <code>__builtin_shufflevector</code> and OpenCL shuffle/shuffle2 functions.</p>
<h2 id="implementation-concerns">Implementation concerns</h2>
<h3 id="aliasing">Aliasing</h3>
<p>Traditionally, some vendor-specific APIs, such as the Intel intrinsics, have allowed aliasing between vectors and scalars.</p>
<p><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4184.pdf">N4184</a> suggests allowing scalars to alias vectors, but not the other way around. Let’s consider both sides.</p>
<h4 id="vector-aliasing-scalars">Vector aliasing scalars</h4>
<p>Vectors aliasing scalars is mostly useful to be able to write code like this:</p>
<pre><code>void process(float* my_aligned_data)
{
    simd_vector&lt;float&gt;* my_vector_data = reinterpret_cast&lt; simd_vector&lt;float&gt;* &gt;(my_aligned_data);
    // manipulate my_vector_data...
}</code></pre>
<p>This allows to treat existing memory as if being vectors without having to go through the overhead of explicit load/store logic. While some users have requested this feature in Boost.SIMD quite adamently, it seems unnecessary in the presence of iterator or range adaptors.</p>
<p>The main advantage of allowing this is to pass a vector of raw memory by reference with maximum efficiency (without this, some compilers will require copying the memory on the stack).</p>
<h4 id="scalars-aliasing-a-vector">Scalars aliasing a vector</h4>
<p>Scalars aliasing vectors is essentially this</p>
<pre><code>simd_vector&lt;float&gt; v;
float* p = &amp;v[0];
p[3] = 42.f;</code></pre>
<p>While this gives a nice interface, this actually forces a vector, which is supposed to be in a register, to go into memory, which is generally undesired. For maximum optimization opportunities, it would be best if everything could stay in registers, and only load/store goes to memory.</p>
<p>Moreover, implementing this requires using unions or special compiler attributes like <code>__may_alias__</code>; extensive testing of this approach shows that this tends to be fragile with a lot of compiler versions and targets.</p>
<p><strong>Conclusion</strong>: not allowing any aliasing gives maximum opportunity for optimization and fits well with the idea that vectors should be registers</p>
<p><strong>Suggestion</strong>: make operator[] be read-only and return by value, only allow access with memory through load/store.</p>
<h3 id="size-of-simd-vector-object">Size of SIMD vector object</h3>
<p>To satisfy the principle of least surprise, one might argue that <code>simd_vector&lt;T, N&gt;</code> should be the same size as <code>T[N]</code>, and possibly also compatible layout (see aliasing).</p>
<p>However it appears interesting to let implementations have the freedom to implement say <code>simd_vector&lt;float, 2&gt;</code> with the same backend as <code>simd_vector&lt;float, 4&gt;</code>.</p>
<p><strong>Suggestion</strong>: <code>sizeof(simd_vector&lt;T, N&gt;) &gt;= sizeof(T) * N</code></p>
<h3 id="impact-of-calling-conventions">Impact of calling conventions</h3>
<p>Since <code>simd_vector</code> is defined as a class, it would use the standard calling convention for user-defined types, which with many ABIs is to pass the value through the stack. Some ABIs also do not allow passing by value such a type due to its alignment requirements, and require passing by const-reference reference instead.</p>
<p>This is undesirable and very negatively affects performance, so much that experience has shown that using attributes such as <code>__forceinline</code> or <code>__attribute__((always_inline))</code> was necessary to obtain acceptable performance, as the penalty for going through the stack is important and not taken into account by the compiler inliner.</p>
<p>As such, a pure library implementation might be limited and the library might require compiler support so that the <code>simd_vector</code> types can be passed to functions with maximum efficiency.</p>
<h2 id="syntax">Syntax</h2>
<h3 id="mask-and-bools">Mask and bools</h3>
<p>Papers <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4184.pdf">N4184</a> and <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4185.pdf">N4185</a> use <code>Vector&lt;T&gt;</code> to represent vectors of arithmetic values and <code>Mask&lt;T&gt;</code> to represent vectors of boolean values resulting from operations on values of type <code>Vector&lt;T&gt;</code>.</p>
<p>It suggests alternatives, like <code>Vector&lt;bool&gt;</code>, which isn’t sufficient, but it doesn’t suggest the following alternative: <code>Vector&lt;Mask&lt;T&gt;&gt;</code> or, which a different naming convention, <code>simd_vector&lt;simd_bool&lt;T&gt;&gt;</code>. This has the advantage that vectors of boolean results remain vectors and behave similarly to their arithmetic counterparts.</p>
<h3 id="expression-templates-for-syntactic-sugar">Expression templates for syntactic sugar</h3>
<h4 id="conditionals">Conditionals</h4>
<p>Paper <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4185.pdf">N4185</a> suggests using expression templates to enable the following syntax</p>
<pre><code>a(cond) = expr;</code></pre>
<p>as a shortcut for</p>
<pre><code>a = iif(cond, expr, a);</code></pre>
<p>Requiring the use of expression templates is not without problems:</p>
<ul>
<li>it makes the return type of expressions not straightforward, results are not of the expected logical type but a proxy</li>
<li>problems with auto and lifetime of objects</li>
<li>additional abstraction and indirections which can make it harder for the compiler to optimize (had major problems with this on MSVC)</li>
<li>bad compatibility with user-written functions</li>
</ul>
<p><strong>Suggestion</strong>: extend the language to provide an overloadable conditional operator so that one could write</p>
<pre><code>a = cond ? expr : a;</code></pre>
<p>or even</p>
<pre><code>a := cond ? expr;</code></pre>
<h4 id="operator-dot">Operator dot</h4>
<p><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4184.pdf">N4184</a> introduces special syntax based overloading <code>operator[]</code> to call operator dot for vectors of structures.</p>
<p><strong>Suggestion</strong>: build a satisfying way to overload operator dot in the language, see <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0060r0.html">P0060R0</a>.</p>
<h2 id="references">References</h2>
<dl>
<dt><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3571.pdf">N3571</a></dt>
<dd>A Proposal to add Single Instruction Multiple Data to the Standard Library
</dd>
<dt><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4184.pdf">N4184</a></dt>
<dd>SIMD Types: The Vector Type &amp; Operations
</dd>
<dt><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4185.pdf">N4185</a></dt>
<dd>SIMD Types: The Mask Type &amp; Write-Masking
</dd>
<dt><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4454.pdf">N4454</a></dt>
<dd>SIMD Types Example: Matrix Multiplication
</dd>
<dt><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0060r0.html">P0060R0</a></dt>
<dd>Function Object-Based Overloading of Operator Dot
</dd>
</dl>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Bader, David A., and Virat Agarwal. “FFTC: fastest Fourier transform for the IBM cell broadband engine.” High Performance Computing–HiPC 2007. Springer Berlin Heidelberg, 2007. 172-184.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Inoue, Hiroshi, et al. “AA-sort: A new parallel sorting algorithm for multi-core SIMD processors.” Proceedings of the 16th International Conference on Parallel Architecture and Compilation Techniques. IEEE Computer Society, 2007.<a href="#fnref2">↩</a></p></li>
</ol>
</div>
</div>

</body>
</html>
